{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a928836a-81e2-41dc-9b09-c06324de5e4c",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a467299-74c5-4cc8-9097-52fc7343b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lasso Regression is the Regularization technique also called L1 norm used to reduce overfitting,\n",
    "## It adds lambda*|slope| to the cost function.\n",
    "## It is different from other Regression technique in the sense that it can be used for large  number of independent variable where it makes the coeficients of redundant\n",
    "## variables to 0 thus used for feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7c48b-7cf4-4c39-b6f7-a215e56e2fb4",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1cca7f5-b74e-4a1a-8394-21ef4cb53d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## As discussed in above it makes the coeficients of non useful variable to 0, \n",
    "## Lasso Regression performs both variable selection and regularization simultaneously, by adding an L1 penalty to the objective function,\n",
    "## which leads to a sparse model with many coefficients being exactly zero.\n",
    "## The coefficients of the non-zero variables can be interpreted as the relative importance of each variable in predicting the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "677fb573-6ad5-4c71-8d01-ed5cca110a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the main advantage of using Lasso Regression in feature selection is that it can effectively identify the most important variables\n",
    "## while discarding the less important ones, resulting in a simpler and more interpretable model that can improve the model's generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c066fd-172e-42ca-82e1-7c126723739c",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8eac802-bee9-4e4d-bb49-154aa7ed51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The coefficients of a Lasso Regression model can be interpreted in a similar way to those of a standard linear regression model. \n",
    "## However, due to the L1 penalty used in Lasso Regression, some coefficients may be exactly zero,\n",
    "## indicating that the corresponding variable was not selected in the model. \n",
    "## The coefficients of the non-zero variables can be interpreted as the relative importance of each variable in predicting the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fbf7090-c68b-4b2d-9535-2ba1c086a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The magnitude of the coefficient estimates can be used to assess the strength of the relationship between each predictor variable and the response variable. \n",
    "## A positive coefficient indicates a positive relationship, meaning that an increase in the predictor variable is associated with an increase in the response variable,\n",
    "## while a negative coefficient indicates a negative relationship, meaning that an increase in the predictor variable is associated with a decrease in the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac49b91-ddfa-4568-9cff-d88a8cab07b0",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b443c-dddd-4f33-9334-ed06d193d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lambda: The Lambda parameter controls the strength of the L1 penalty and determines the balance between the degree of regularization and the fit to the training data.\n",
    "## A higher Lambda value results in a more regularized model, where more coefficients are shrunk towards zero, while a lower Lambda value allows more coefficients to be non-zero. \n",
    "## The optimal value of Lambda can be determined through cross-validation.\n",
    "\n",
    "## Max iterations: The maximum number of iterations controls the number of times the Lasso Regression algorithm iteratively updates the coefficient estimates.\n",
    "## If the maximum number of iterations is not reached before convergence, the algorithm stops early."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a69cb1-32af-4311-a2ec-8dfb3a641daf",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769aa69d-d201-460f-aced-cc9e3e49f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In general Lasso Regression is used mainly for Linear Regression Problems where ther is linear relationship between dependent and independent variables.\n",
    "## However it is possible to use Lasso Regression for non-linear regression problems by introducing non-linear transformations of the predictor variables.\n",
    "## One way to do this is by using basis functions, which are functions that transform the original predictor variables into a higher-dimensional feature space.\n",
    "## For example, polynomial basis functions can be used to introduce non-linear terms of the predictor variables, such as x^2, x^3, and so on, into the regression mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82ab92-e2fd-4b6c-a7d1-40d2a7cacb5e",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63d81293-5bdf-47b2-b6fa-faa8016db56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Ridge Regression uses an L2 penalty, which adds a penalty term proportional to the square of the magnitude of the coefficients\n",
    "## In contrast, Lasso Regression uses an L1 penalty, which adds a penalty term proportional to the absolute value of the magnitude of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b449d159-1960-4f99-8aa2-f7b991f763e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge Regression is used where multicollinearity is problem\n",
    "## Lasso Regression can be used for feature Selection which shrinks non useful variable coeficients to 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c2acb0-7a84-4ca7-964f-79a99dad4252",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce11680f-73c9-403f-bc63-ff5ce50d760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No Lasso Regression does not hanlde Multicollinearity , It can be handled by Ridge regression.\n",
    "## If large number of variables are there and also multicollinearity is the problem then we can use Elasticnet regression which add both L1 and L2 penalty term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae4f3ce-c169-48b3-b72a-3315e73c5763",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b43154-ccf6-427a-bebe-180e8f37987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choosing the optimal value of the regularization parameter (lambda) in Lasso Regression involves finding the right balance\n",
    "## between model complexity and model performance. A small value of lambda will result in a model with more coefficients,\n",
    "## while a large value of lambda will result in a model with fewer coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff0b184-08db-4e0c-b235-ea237a38b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To select optimal value we can use cross validation, hyperparameter tuning method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7d1e7-2f01-4db0-bc87-65a979d8424a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
