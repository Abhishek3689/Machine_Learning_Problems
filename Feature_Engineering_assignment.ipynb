{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0800140-48ad-4cba-a705-2472928ea378",
   "metadata": {},
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f463ee56-e2a6-4834-a3b3-6f964f65814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing values are missing data  for some variable/features in the dataset.These are represented by  NAN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f9e025-4ffa-47df-80d2-b291e93201b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest,XGboost,Decision Tree, K-Nearest Neighbour algorithms are not afected by missing values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad3901-3a38-49fb-9f98-3fe196aefebe",
   "metadata": {},
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45159380-725d-47af-b97b-f4aa827b2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are Basically 3 Types to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e78ed2-96c2-4e18-a848-29bde7d9d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mean\n",
    "### Median\n",
    "### Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce31b280-f8c9-4745-ad6d-4f1123dd521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6755c25-0188-4cc0-a865-e353d44d76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({\"A\":[12,None,45,35,25,None],\"B\":[45,80,60,50,None,75],\"C\":['Fail','Pass','Fail','Pass',None,'Pass']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76320025-3e7f-4b03-8b13-218410cae7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A     B     C\n",
       "0  12.0  45.0  Fail\n",
       "1   NaN  80.0  Pass\n",
       "2  45.0  60.0  Fail\n",
       "3  35.0  50.0  Pass\n",
       "4  25.0   NaN  None\n",
       "5   NaN  75.0  Pass"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b9ad20-f0dd-4911-aa35-410b67b79393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    2\n",
       "B    1\n",
       "C    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b69b8b8-8274-43a2-a4c1-5576755146d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.00\n",
       "1    29.25\n",
       "2    45.00\n",
       "3    35.00\n",
       "4    25.00\n",
       "5    29.25\n",
       "Name: A, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A'].fillna(df['A'].mean()) ## Column A Nan Value is fiiled with mean 29.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb1fd511-15c7-4a27-a7d0-7c1eee92dc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45.0\n",
       "1    80.0\n",
       "2    60.0\n",
       "3    50.0\n",
       "4    60.0\n",
       "5    75.0\n",
       "Name: B, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['B'].fillna(df['B'].median()) ### Column B Nan value is filled with Median 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b37de3-6faa-4ff2-99e4-2fa0980dbc7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fail\n",
       "1    Pass\n",
       "2    Fail\n",
       "3    Pass\n",
       "4    Pass\n",
       "5    Pass\n",
       "Name: C, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['C'].fillna(df['C'].mode()[0]) ## Here in place of Nan/None value mode 'Pass' is filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d13122-0a85-46dc-a699-9be163ce9444",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "016a5ab0-67b9-444e-8035-a1795c0b3e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imbalanced dataset is the dataset where dependent feature has imbalances in their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e64dd63-6b1f-4099-9770-ef04995cb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For example if we have 100 rows with binary classification as 0 and 1 , Out of these 100 records , 90 records has labelled as 0 and 10 records has 1 value,\n",
    "## then we have imbalanced in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2160df95-0013-43eb-a034-97d011184cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Most imformation may get lost if not handled properly\n",
    "## If it is not handled then it may mislead the information. WE will not be accurately predictng the outputs as major class data records has higher impact "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e0d94c-c149-47c1-a2d5-37aa00d31da8",
   "metadata": {},
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "466c4f1b-feb1-4130-a87a-038ccc160011",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Up-Sampling is the technique by which we increase the records of minority class equal to majority class labels by random sampling copy /Synthetic data creation\n",
    "### From above example  minority 10 Instances of class 1 we create 90 instances of class 1 so total of 180 instances  will be avaialble for training purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4904e3b-ce42-4c03-ac81-db26dbc7785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downsampling is the technique by which we decrease the records of majority class equal to minority class by random sampling \n",
    "## from above example. 90 instances of class 0  reduced down to 10 records so total of 20 instances to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05be08e-58d8-483e-adc9-f42e8a39e64c",
   "metadata": {},
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c12161e-8ee4-4060-aef6-7ac98964f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Data augmentation is a set of techniques to artificially increase the amount of data by generating new data points from existing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fda66283-d84a-436d-bae4-fdf802e49b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Smote is synthetic minority over-sampling Technique used in machine learning to address imbalanced datasets\n",
    "## where the minority class has significantly fewer instances than the majority class.\n",
    "## SMOTE involves generating synthetic instances of the minority class by interpolating between existing instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfaadd6-e1d6-469d-8673-08e9ebaf3c70",
   "metadata": {},
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75adbd82-fb58-4a9e-a5b9-636a31c6dbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## An outlier is an observation that lies an abnormal distance from other values in a random sample from a population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50e3075e-2994-48c2-adb8-98f29e7b7b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## They vary significantly from other data observations and not normally distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a025108-d934-4e38-84ee-80deeb2b9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The outliers are abnormal o it will misinterpret the result , and it can deviate from actual performance which are misleading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa2368-e437-45e9-84ec-806f425fc853",
   "metadata": {},
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef826895-6889-474c-8373-05ef8aa5298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### if the data is numerical and it is normally distributed we can use mean method to fill nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe593eeb-da76-4686-912a-8ee69532483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### if data is numericall but some abnormality is showing we can use median to fill the Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98eea5e-a015-4e9f-b8b9-5bd3a6698f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If data is categorical then we can use Mode method to fill the Nan Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5556781-2560-4265-878d-d2fcf4b6159c",
   "metadata": {},
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c11a3748-7fd2-4581-8fc0-08b1535b1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I will use distribution plot to see how the plot is showing, if data is normally distributed we can say there is some pattern and related o each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c318e6b5-802d-4d31-a752-3ed9235d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If distribution is not normal then their will be randomness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50e33a8-7c1a-469f-a90a-1e64c0cac017",
   "metadata": {},
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74d343ab-eded-43ac-b659-153f61984f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will Use SMOTE technique for data augmentation before  building  model, This will ensure that my data is balanced.\n",
    "## it is used using  imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b57a18-dbb8-4b47-87b0-31f4522a589b",
   "metadata": {},
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1445a3a4-fd41-4bdc-9df4-dea8a4b2f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I will use random sampling from majority class to downsample equals to minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f94a0f91-e572-442f-949d-4a85683ca99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### for eg in 1000 records 900 are for majority class then i will use df.sample(100) so that both class has equal instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baa1652-b859-4e92-8e6e-5615056ee9fe",
   "metadata": {},
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64edec42-5e51-4cec-9efa-904c10f491b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I will use SMOTE technique as discussed above to up sample the minority class.  AS it involves synthetic data creation using K nearest neighbours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548c182d-9ce5-48ad-8972-dc91324e5f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
